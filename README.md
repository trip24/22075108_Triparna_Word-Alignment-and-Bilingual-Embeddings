# ğŸ§‘â€ğŸ“ **BTP Project â€” Word Alignment and Bilingual Word Embeddings**

**Author:** *Triparna Samanta*

**Roll Number:** *22075108*

**Institution:** *IIT(BHU),Varanasi*

**BTP Title:** **Encoderâ€“Decoder Word Alignment**

**Professor:** *Anil Singh*


# ğŸ“˜ **Bilingual Embedding Pipeline for Hindiâ€“English**

*A complete pipeline using Parallel â†’ Comparable â†’ Monolingual corpora, Word Alignment, Embedding Alignment, Visualization, and Dictionary Generation.*

---

## ğŸ“„ **Table of Contents**

1. [Project Overview](#project-overview)
2. [Datasets Used](#datasets-used)
3. [System Architecture](#system-architecture)
4. [Methodology](#methodology)
5. [Pipeline Stages](#pipeline-stages)

   * Parallel Corpora Stage
   * Comparable Corpora Stage
   * Monolingual Corpora Stage
6. [Word Alignment](#word-alignment)
7. [Embedding Alignment](#embedding-alignment)
8. [Dictionary Generation](#dictionary-generation)
9. [Visualization](#visualization)
10. [File Structure](#file-structure)
11. [How to Run the Project](#how-to-run-the-project)
12. [Final Outputs](#final-outputs)
13. [Future Work](#future-work)
14. [Project Report & Presentation](#project-report--presentation)

---

# ğŸ§  **Project Overview**

This project builds **high-quality bilingual embeddings** for the Hindiâ€“English language pair using:

* Parallel corpora
* Comparable corpora
* Monolingual corpora

The pipeline includes:

* Word alignment using **Encoder-Decoder Model**
* Bilingual embedding alignment using **Orthogonal Procrustes**
* Training FastText embeddings
* Visualization using t-SNE
* Automatically generated bilingual & monolingual dictionaries

This follows the complete instruction given by the supervisor:

> â€œFirst use parallel corpora â†’ then comparable corpora â†’ then monolingual corpora,
> use word alignment, align embeddings, visualize them and finally create bilingual and monolingual dictionaries.â€

---

# ğŸ“¦ **Datasets Used**

### **1ï¸âƒ£ Parallel Corpus â€“ AI4Bharat Samanantar**

Source:
ğŸ‘‰ [https://samanantar.com/](https://samanantar.com/) (AI4Bharat)

* Contains Hindiâ€“English sentence-aligned data
* Used to train baseline bilingual embeddings
* Used for Encoder Decoder word alignment

Your extracted files:

* `data/en.txt`
* `data/hi.txt`

---

### **2ï¸âƒ£ Comparable Corpus â€“ Wikipedia Articles (Manually Collected)**

Since comparable corpora need to be *topically similar but not sentence-aligned*,
you manually collected Wikipedia pages in:

* Sports
* Technology
* Education
* Miscellaneous topics

You copy/pasted these into:

* `data/comp_en.txt`
* `data/comp_hi.txt`

These are **independently shuffled** to simulate non-parallel comparable corpora.

---

### **3ï¸âƒ£ Monolingual Corpus â€“ IIT Bombay English & Hindi Monolingual Dataset**

Source: IITB Monolingual Corpora
ğŸ‘‰ [https://www.cfilt.iitb.ac.in/iitb_parallel/](https://www.cfilt.iitb.ac.in/iitb_parallel/)

Used to improve:

* Language modeling quality
* Richness of embedding space
* Quality of bilingual dictionary after projection

Stored in:

* `data/en_mono.txt`
* `data/hi_mono.txt`

---

# ğŸ§¬ **System Architecture**

```
          Parallel Corpus (Samanantar)
                     â”‚
             Sentence Alignment
                     â”‚
                Encoder Decoder Model
             (Word Alignments)
                     â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                               â”‚
Parallel Embeddings            Comparable Corpora
(FastText)                     (Shuffled Wikipedia)
       â”‚                               â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
  Train Parallel + Comparable Embeddings
                     â”‚
             Procrustes Alignment
                     â”‚
            Comparable-Aligned Space
                     â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                               â”‚
  Monolingual EN Corpus       Monolingual HI Corpus
  (IIT Bombay)                (IIT Bombay)
       â”‚                               â”‚
        Train High-Capacity Monolingual FastText
                     â”‚
             Procrustes Mapping
                     â”‚
      Monolingual-Aligned Bilingual Space
                     â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                                â”‚
 Bilingual Dictionary             Monolingual Dictionary
 (ENâ†’HI / HIâ†’EN)                 (Synonym Lists)
```

---

# ğŸ”¬ **Methodology**

This project follows a **3-stage pipeline**:

1. **Parallel Corpus Stage**
2. **Comparable Corpus Stage**
3. **Monolingual Corpus Stage**

Every stage trains its own embeddings, aligns them, visualizes them, and generates dictionaries.

### Core technologies used:

* **FastText Skip-gram embeddings**
* **Encoder Decoder based word alignment**
* **Orthogonal Procrustes mapping**
* **t-SNE visualization**
* **Cosine similarity search for dictionary generation**

---

# ğŸš¦ **Pipeline Stages**

---

## 1ï¸âƒ£ **Parallel Corpus Stage (Base Model)**

Using **Samanantar parallel corpus**:

âœ” Train FastText EN/HI embeddings
âœ” Extract word alignments using Encoder Decoder
âœ” Build seed dictionary (`seed.txt`)
âœ” Learn mapping matrix using Procrustes
âœ” Visualize aligned vs unaligned spaces
âœ” Generate first bilingual dictionary

---

## 2ï¸âƒ£ **Comparable Corpus Stage (Rich Semantic Space)**

Using **Wikipedia comparable corpora**:

âœ” Shuffle English & Hindi independently
âœ” Combine parallel + comparable corpora
âœ” Train improved FastText embeddings
âœ” Align with the same seed dictionary
âœ” Visualize comparable-enhanced embedding space
âœ” Generate comparable-based bilingual dictionary

---

## 3ï¸âƒ£ **Monolingual Corpus Stage (Best Model)**

Using **IIT Bombay monolingual corpora**:

âœ” Train 300-dim high-capacity FastText embeddings
âœ” Align them using parallel seed dictionary
âœ” Visualize monolingual-aligned bilingual space
âœ” Generate best-quality bilingual dictionary
âœ” Generate monolingual synonym dictionaries

---

# ğŸ”— **Word Alignment**

We use **Encoder Decoder based Word Alignment**:

* Model: Encoder Decoder Architecture
* Matching method: `mwmf` (Many-to-Many Maximum F-score Word Matching)
* Produces high-quality bilingual word pairs

Output file:

```
output/seed.txt
```

This seed is essential for:

* Comparable embedding alignment
* Monolingual embedding alignment

---

# ğŸ¯ **Embedding Alignment**

We align EN/HI embeddings using **Orthogonal Procrustes**:

[
R = \arg\min_R |XR - Y| \quad \text{s.t. } R^\top R = I
]

This produces alignment matrices:

```
output/R.npy         (parallel)
output/R_all.npy     (parallel + comparable)
output/R_mono.npy    (monolingual)
```

---

# ğŸ“˜ **Dictionary Generation**

Three bilingual dictionaries:

* `dictionary.json` (parallel-only)
* `dictionary_all.json` (parallel + comparable)
* `dictionary_mono.json` (monolingual-enhanced)

Two monolingual dictionaries:

* `en_monodict.json`
* `hi_monodict.json`

Generated using cosine similarity of aligned embeddings.

---

# ğŸ¨ **Visualization**

t-SNE plots generated:

```
output/tsne_unaligned.png
output/tsne_aligned.png
output/tsne_all_aligned.png
output/tsne_mono_aligned.png
```

These show the quality of alignment improving through:

parallel â†’ comparable â†’ monolingual.

---

# ğŸ“ **File Structure**

```
BilingualProject/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ en.txt                    # Samanantar parallel
â”‚   â”œâ”€â”€ hi.txt
â”‚   â”œâ”€â”€ comp_en.txt              # Comparable corpora (Wikipedia)
â”‚   â”œâ”€â”€ comp_hi.txt
â”‚   â”œâ”€â”€ en_train_all.txt         # Parallel + comparable
â”‚   â”œâ”€â”€ hi_train_all.txt
â”‚   â”œâ”€â”€ en_mono.txt              # IIT Bombay monolingual
â”‚   â”œâ”€â”€ hi_mono.txt
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ model.py  
|
|         
â”œâ”€â”€ output/
â”‚   â”œâ”€â”€ eng.bin                  # Parallel embeddings
â”‚   â”œâ”€â”€ hin.bin
â”‚   â”œâ”€â”€ eng_all.bin              # Parallel + comparable embeddings
â”‚   â”œâ”€â”€ hin_all.bin
â”‚   â”œâ”€â”€ eng_mono.bin             # Monolingual embeddings
â”‚   â”œâ”€â”€ hin_mono.bin
â”‚   â”œâ”€â”€ seed.txt                 # Word alignments
â”‚   â”œâ”€â”€ R.npy                    # Alignment matrices
â”‚   â”œâ”€â”€ R_all.npy
â”‚   â”œâ”€â”€ R_mono.npy
â”‚   â”œâ”€â”€ dictionary.json
â”‚   â”œâ”€â”€ dictionary_all.json
â”‚   â”œâ”€â”€ dictionary_mono.json
â”‚   â”œâ”€â”€ en_monodict.json
â”‚   â”œâ”€â”€ hi_monodict.json
â”‚   â”œâ”€â”€ tsne_unaligned.png
â”‚   â”œâ”€â”€ tsne_aligned.png
â”‚   â”œâ”€â”€ tsne_all_aligned.png
â”‚   â”œâ”€â”€ tsne_mono_aligned.png
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ prepare_parallel.py
â”‚   â”œâ”€â”€ make_comparable.py
â”‚   â”œâ”€â”€ make_train_all.py
â”‚   â”œâ”€â”€ train_embeddings.py
â”‚   â”œâ”€â”€ train_embeddings_all.py
â”‚   â”œâ”€â”€ train_embeddings_mono.py
â”‚   â”œâ”€â”€ extract_seed.py
â”‚   â”œâ”€â”€ align_embeddings.py
â”‚   â”œâ”€â”€ align_embeddings_all.py
â”‚   â”œâ”€â”€ align_embeddings_mono.py
â”‚   â”œâ”€â”€ generate_dictionary.py
â”‚   â”œâ”€â”€ generate_dictionary_all.py
â”‚   â”œâ”€â”€ generate_dictionary_mono.py
â”‚   â”œâ”€â”€ generate_monolingual_dicts.py
â”‚   â”œâ”€â”€ visualize_unaligned.py
â”‚   â”œâ”€â”€ visualize_aligned.py
â”‚   â”œâ”€â”€ visualize_all_aligned.py
â”‚   â”œâ”€â”€ visualize_mono_aligned.py
â”‚
â””â”€â”€ README.md
```

---

# â–¶ï¸ **How to Run the Project**

### 1. Create virtual environment

```bash
python3 -m venv venv
source venv/bin/activate
pip install fasttext simalign numpy scipy sklearn matplotlib
```

---

### 2. Prepare parallel corpus

```bash
python scripts/prepare_parallel.py
```

---

### 3. Extract word alignments

```bash
python scripts/extract_seed.py
```

---

### 4. Train parallel embeddings

```bash
python scripts/train_embeddings.py
```

---

### 5. Align & visualize parallel embeddings

```bash
python scripts/align_embeddings.py
python scripts/visualize_aligned.py
```

---

### 6. Create comparable corpora

```bash
python scripts/make_comparable.py
python scripts/make_train_all.py
```

---

### 7. Train comparable embeddings

```bash
python scripts/train_embeddings_all.py
python scripts/align_embeddings_all.py
python scripts/visualize_all_aligned.py
```

---

### 8. Train monolingual embeddings

```bash
python scripts/train_embeddings_mono.py
python scripts/align_embeddings_mono.py
python scripts/visualize_mono_aligned.py
```

---

### 9. Generate dictionaries

```bash
python scripts/generate_dictionary.py
python scripts/generate_dictionary_all.py
python scripts/generate_dictionary_mono.py
python scripts/generate_monolingual_dicts.py
```

---

# ğŸ **Final Results**

### ğŸ”¤ Embeddings

* Parallel
* Comparable
* Monolingual

### ğŸ§­ Alignments

* Mapping matrices
* Word alignment seeds

### ğŸ“˜ Dictionaries

* Parallel dictionary
* Comparable-enhanced dictionary
* Monolingual-enhanced dictionary
* Monolingual synonym dictionaries

### ğŸ¨ Visualizations

* Parallel (before & after alignment)
* Comparable-enhanced
* Monolingual-enhanced

---

# ğŸš€ **Future Work**

* Use contextual embeddings (mBERT, XLM-R, LaBSE)
* Train full MUSE unsupervised bilingual mapping
* Use CSLS instead of cosine similarity
* Build sentence-level dictionaries
* Integrate with Bhaashik annotation tool
* Add WordNet-style semantic graph construction

---

# ğŸ“ **Project Report & Presentation**

### ğŸ“Œ **Presentation (Google Drive link)**

ğŸ‘‰ https://drive.google.com/drive/folders/1Hd0S3gwncXq4ADlcNMk2uMsBL4byHJXl?usp=drive_link

### ğŸ“Œ **Full PDF Report**

ğŸ‘‰ https://drive.google.com/drive/folders/1Hd0S3gwncXq4ADlcNMk2uMsBL4byHJXl?usp=drive_link

### ğŸ“Œ **Final Paper (Optional)**

ğŸ‘‰ https://drive.google.com/drive/folders/1Hd0S3gwncXq4ADlcNMk2uMsBL4byHJXl?usp=drive_link

---

# ğŸ™Œ **End of README**


"# 22075108_Triparna_Word-Alignment-and-Bilingual-Embeddings" 
